{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd9a764-db4c-41f7-94f2-5fb78542fcca",
   "metadata": {},
   "source": [
    "# Quick Overview of RLFH\n",
    "\n",
    "The performance of Language Models until GPT-3 was kind of amazing as-is. What the models of were essentially lacking was the aspect of **alignment**. The language generation aspect was particularly challenging due to heavy hallucinations, toxicity, etc.\n",
    "\n",
    "The authors of the seminal work **[InstructGPT](https://arxiv.org/pdf/2203.02155)** basically focussed on this aspect of aligning the language models to user's intructions (hence the name!). Their work showcased how we can further fine-tune such models in a supervised way leverage human feedback and reinforcement learning to align them.\n",
    "\n",
    "## High-Level Overview of the Setup\n",
    "\n",
    "<img src=\"./assets/instruct_gpt_rlhf.png\">\n",
    "\n",
    "> Source: https://arxiv.org/pdf/2203.02155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a0b86-baa5-49fd-b5b2-cb8a93aeacbc",
   "metadata": {},
   "source": [
    "## Key Concepts:\n",
    "\n",
    "- **Reinforcement Learning (RL)**: A machine learning paradigm where an agent learns to make decisions by performing actions and receiving _rewards or penalties_ .\n",
    "- **Human Feedback**: Evaluations provided by humans that guide the learning process, ensuring the model's outputs align with human expectations and preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe465e94-5116-4ada-8b4b-bcc2aaffe6d1",
   "metadata": {},
   "source": [
    "## How Does this Actually Work? Show Me Examples Please?\n",
    "\n",
    "### Standard Supervised Learning:\n",
    "- Input: \"Generate a story about a dragon and a knight.\"\n",
    "- Output: The model generates a story based on its training data.\n",
    "\n",
    "\n",
    "### Reinforcement Learning From Human Feedback:\n",
    "- Input: \"Generate a story about a dragon and a knight.\"\n",
    "- Initial Output: The model generates a story.\n",
    "- Human Feedback: A human rates the story on coherence, creativity, and engagement.\n",
    "- Adjusted Output: The model refines its story generation based on the feedback, leading to more engaging and coherent stories over time.\n",
    "\n",
    "As pointed out in the figure above, one of the ways of bringing this alignment is through:\n",
    "- Training a **reward model** using a Human labelled dataset.\n",
    "    - This dataset basically contains rank ordered responses to different inputs to the model\n",
    "- The reward model learns to predict human preferences based on the provided human feedback by assigning a score (reward) to the outputs of the language model.\n",
    "-  The output of the reward model is then used to update the policy of the language model (agent) to align with the human feedback (exploration vs exploitation)\n",
    "\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_overview.png\">\n",
    "\n",
    "> Source: https://huggingface.co/docs/trl/en/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670ad0a-0feb-4893-94ef-0582aa14c0a1",
   "metadata": {},
   "source": [
    "## PPO vs DPO\n",
    "\n",
    "There are different ways of performing policy optimisation. The original work follows Proximal Policy Optimisation which requires a separate reward model to tune the Language Model. DPO or Direct Policy Optimisation directly applies updates to the language model thus removing the need for a separate reward model.\n",
    "\n",
    "> Read more about RL and KL Divergence to understand the topic better\n",
    "\n",
    "\n",
    "> The KL-divergence between the two outputs is used as an _additional reward signal_ to make sure the generated responses don’t deviate too far from the reference language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895576f-f530-4268-b13d-a2898c160c6d",
   "metadata": {},
   "source": [
    "# Quick Hello World Using PPO\n",
    "\n",
    "> Can we improve alignment of Phi-1.5?\n",
    "\n",
    "> Adapted from:\n",
    "> [[1](https://huggingface.co/docs/trl/en/quickstart)], [[2](https://github.com/antndlcrx/oxford-llms-workshop/blob/main/materials/seminars/day_3/8_LLMs%20alignment%20with%20RLHF.ipynb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c1c30-1627-4373-affb-6ae932062c31",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aac1de-86c7-41f6-8bcf-0871c8e7e75c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.43.3)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.9.6)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.33.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
      "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.1.0+cu118)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.65.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.1.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers trl datasets accelerate matplotlib  tensorboard tensorboardx seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9fccb-8f74-4055-837a-290bc88d7abc",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb50023-862f-4732-9810-847ed649492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choices\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2c94d-bf36-4c16-aa91-d422eed1a076",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a741d7a7-dc43-45aa-905b-c0950c90efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_length = 5\n",
    "text_output_length = 20\n",
    "seed = 42\n",
    "\n",
    "sentiment_pipe_kwargs = {\n",
    "    \"top_k\": None, \n",
    "    \"function_to_apply\": \"none\",\n",
    "    'return_all_scores':False\n",
    "}\n",
    "# microsoft/Phi-3-mini-4k-instruct\n",
    "ppo_config = PPOConfig(\n",
    "    model_name=\"microsoft/phi-2\", \n",
    "    steps=200,\n",
    "    learning_rate=1.41e-5, \n",
    "    remove_unused_columns=False,\n",
    "    log_with=\"tensorboard\",\n",
    "    project_kwargs={\"logging_dir\": \"./logs\"},\n",
    ")\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    #\"max_new_tokens\": text_output_length,\n",
    "    #\"eos_token_id\": -1,\n",
    "}\n",
    "\n",
    "ALIGNED_MODEL_NAME = f\"aligned-{ppo_config.model_name.split('/')[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c370fbf6-9688-4ef4-8766-e818d50365e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa70bc7b6ac4d09b0d9c0d1ed102d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421f780-6e7e-4a18-877b-d17d05a55857",
   "metadata": {},
   "source": [
    "## Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f832e9-0109-49cd-afce-c2b7940b2081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91000a656924dbdb364e67f9ad0dde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.phi.modeling_phi.PhiForCausalLM'> model is loaded from 'microsoft/phi-2', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(ppo_config.model_name,cache_dir=\"/workspace/\")\n",
    "# create a reference model\n",
    "ref_model = create_reference_model(model, num_shared_layers=6)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ppo_config.model_name,cache_dir=\"/workspace/\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "generation_kwargs[\"pad_token_id\"] = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f326a-29fb-4c71-825c-f646d1a22baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edff3ac-04d3-4834-bd78-ce71204490aa",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd06c08d-97a6-4211-9281-b9994b15eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(\n",
    "    tokenizer, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8\n",
    "):\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0de8e00-8083-4b8a-9632-53b29fdff156",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(tokenizer)\n",
    "\n",
    "\n",
    "def data_collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b99af4-7dcb-4bbb-a0a6-4ae052b00462",
   "metadata": {},
   "source": [
    "## Setup PPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed7fe2c-202e-4f26-a0bf-f32fb28f23fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(ppo_config,\n",
    "                         model,\n",
    "                         ref_model,\n",
    "                         tokenizer,\n",
    "                         dataset,\n",
    "                         data_collator=data_collator,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc08b7b-37e5-4086-930f-5141d293580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerator Device=0\n"
     ]
    }
   ],
   "source": [
    "if ppo_trainer.accelerator.num_processes == 1:\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"  \n",
    "else:\n",
    "    device = ppo_trainer.accelerator.device\n",
    "print(f\"Accelerator Device={device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59df473a-8ef4-4075-ad99-1faf93506a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_trainer.accelerator.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66483a3e-e7b0-4acb-b8f8-d61fc046a796",
   "metadata": {},
   "source": [
    "### Setup Reward Model and Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f3030-2639-436a-8e76-fc9ee8c32351",
   "metadata": {},
   "source": [
    "### Reward Assignment\n",
    "\n",
    "The objective is to align our text generation model towards the alignment signal provided.\n",
    "To do so, we need to assign a corresponding reward to each output logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1715dab4-0733-430b-8575-dcff542dce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 2.3350484371185303},\n",
       " {'label': 'POSITIVE', 'score': -2.726576328277588}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the Reward Model\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\",eos_token='</s>')\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \"lvwerra/distilbert-imdb\", tokenizer=distilbert_tokenizer,device=device)\n",
    "\n",
    "# test out the pipeline\n",
    "text = \"this movie was really bad!!\"\n",
    "output = sentiment_pipe(text, **sentiment_pipe_kwargs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346baa6-53a9-4820-9933-f8d1d1962a5f",
   "metadata": {},
   "source": [
    "## Time to Align using RLHF : PPO\n",
    "> Todo add steps overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529ca163-4f12-4a6b-9cc0-df3196dfe45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf2e88d-abb5-4527-b616-63e5e0fe406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_min_length = 10\n",
    "output_max_length = 25\n",
    "num_steps = 5\n",
    "overall_rewards = list()\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5914ba7-bc24-48d7-aa2d-e55630c553c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs[\"pad_token_id\"]= tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c096ba95-3f56-4a9d-83d9-fef3132ff814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0bf0792f9147f0850cab2abb48b8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.0\n",
      "ppo/returns/mean: 2.329904317855835\n",
      "ppo/policy/advantages_mean: -3.260224445966742e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: 1.0848491191864014\n",
      "ppo/returns/mean: 3.011728286743164\n",
      "ppo/policy/advantages_mean: -9.811463641540286e-09\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: 1.9583141803741455\n",
      "ppo/returns/mean: 3.3636350631713867\n",
      "ppo/policy/advantages_mean: -1.5503298200769677e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: 2.7539970874786377\n",
      "ppo/returns/mean: 3.6526408195495605\n",
      "ppo/policy/advantages_mean: 2.8892639392097408e-08\n",
      "---------------------------------------------------------------------------------------------------\n",
      "objective/kl: 4.090468883514404\n",
      "ppo/returns/mean: 4.382137298583984\n",
      "ppo/policy/advantages_mean: -3.667978276666872e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if epoch >= num_steps:\n",
    "        break\n",
    "\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sentiment_pipe_kwargs)\n",
    "    rewards = list()\n",
    "    for output in pipe_outputs:\n",
    "        if output[0]['score']>output[1]['score']:\n",
    "            if output[0]['label'] == 'POSITIVE':\n",
    "                rewards.append(torch.tensor(4*output[0]['score']))\n",
    "            else:\n",
    "                rewards.append(torch.tensor(0.5*output[0]['score']))\n",
    "        elif output[1]['score']>output[0]['score']:\n",
    "            if output[1]['label'] == 'POSITIVE':\n",
    "                rewards.append(torch.tensor(4*output[1]['score']))\n",
    "            else:\n",
    "                rewards.append(torch.tensor(0.25*output[0]['score']))\n",
    "\n",
    "    overall_rewards.append(rewards)\n",
    "    #PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print(\"-\".join(\"\" for x in range(100)))\n",
    "\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc6fff-6b88-46ce-8428-640944228626",
   "metadata": {},
   "source": [
    "### Plot Reward Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "563f73f9-cbd2-4e3b-a4c9-db163d8e8bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAGdCAYAAADey0OaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAseklEQVR4nO3df3BU9b3/8Vd+kB/8SAhEdhOMTRAuFAWChOQG9WrrlkAZb/letcB4L2na0RlLvND1B8SWRAdtANFJEQbUe622t1TqjNh7HRsHtwbHafhhYi4iSrGNJoC7SWiThUQSmt3vH5blriSQE5Kc/YTnY+aMu2c/5/N5nzPAvvzs+REVDAaDAgAAiHDRdhcAAADQF4QWAABgBEILAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARYu0uYCAEAgGdOHFCY8aMUVRUlN3lAACAPggGgzp16pTS09MVHX3peZRhEVpOnDihjIwMu8sAAAD90NjYqKuvvvqS7YZFaBkzZoykL3c6KSnJ5moAAEBf+P1+ZWRkhL7HL2VYhJZzPwklJSURWgAAMExfT+3gRFwAAGAEQgsAADACoQUAABhhWJzTAgCAqbq7u3X27Fm7yxg0MTExio2NHZBbkhBaAACwyenTp3Xs2DEFg0G7SxlUI0eOVFpamuLi4i6rH0ILAAA26O7u1rFjxzRy5EhdddVVw/LmqMFgUF1dXWpublZ9fb2mTJnSp5vI9YbQAgCADc6ePatgMKirrrpKiYmJdpczaBITEzVixAh99tln6urqUkJCQr/74kRcAABsNBxnWL7qcmZXwvoZkF4AAAAGGaEFAAAYgXNaAACIIG8d9g3peK7pjiEd73Iw0wIAACzbunWrMjMzlZCQoLy8PO3fv3/QxyS0AAAAS3bu3Cm3262ysjLV1tZq1qxZKigoUFNT06COS2gBAACWPP3007rnnntUVFSk6dOna/v27Ro5cqReeOGFQR2Xc1r648jv7K7AuqkL7a4AADAMdHV1qaamRiUlJaF10dHRcrlcqq6uHtSxmWkBAAB91tLSou7ubjkc4SfwOhwOeb3eQR2b0AIAAIxAaAEAAH2WmpqqmJgY+Xzhl2b7fD45nc5BHZvQAgAA+iwuLk5z5syRx+MJrQsEAvJ4PMrPzx/UsTkRFwAAWOJ2u1VYWKicnBzl5uaqoqJC7e3tKioqGtRxCS0AAEQQE+5Qu2TJEjU3N6u0tFRer1fZ2dmqrKy84OTcgUZoAQAAlhUXF6u4uHhIx+ScFgAAYARmWix667BPqSda7S6jz7IzxtpdAgAAA4KZFgAAYARCCwAAMAKhBQAAGIHQAgAAjEBoAQAARiC0AAAAIxBaAACAEbhPCwAAkeTI74Z2vKkLLW/yzjvv6Mknn1RNTY0+//xz7dq1S4sXLx742r6CmRYAAGBJe3u7Zs2apa1btw7puMy0AAAASxYuXKiFC63P0FwuZloAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABihX6Fl69atyszMVEJCgvLy8rR///5e27766qvKycnR2LFjNWrUKGVnZ+uXv/xlWJtgMKjS0lKlpaUpMTFRLpdLR48e7U9pAABgkJ0+fVp1dXWqq6uTJNXX16uurk4NDQ2DOq7l0LJz50653W6VlZWptrZWs2bNUkFBgZqamnpsP27cOP34xz9WdXW1Dh48qKKiIhUVFenNN98Mtdm4caM2b96s7du3a9++fRo1apQKCgp05syZ/u8ZAAAYFO+9955mz56t2bNnS5Lcbrdmz56t0tLSQR03KhgMBq1skJeXp7lz52rLli2SpEAgoIyMDN1///1as2ZNn/q44YYbtGjRIq1bt07BYFDp6el64IEH9OCDD0qS2tra5HA49OKLL2rp0qWX7M/v9ys5OVltbW1KSkqysjuWvXXYp9QTvx/UMQZSdsbYL1/0446HAIDBc+bMGdXX1ysrK0sJCQl2lzOoettXq9/flmZaurq6VFNTI5fLdb6D6Gi5XC5VV1dfcvtgMCiPx6MjR47on/7pnyR9OaXk9XrD+kxOTlZeXl6vfXZ2dsrv94ctAABgeLMUWlpaWtTd3S2HwxG23uFwyOv19rpdW1ubRo8erbi4OC1atEjPPPOMvvWtb0lSaDsrfZaXlys5OTm0ZGRkWNkNAABgoCG5emjMmDGqq6vTgQMH9MQTT8jtdquqqqrf/ZWUlKitrS20NDY2DlyxAAAgIll69lBqaqpiYmLk8/nC1vt8Pjmdzl63i46O1uTJkyVJ2dnZ+uijj1ReXq5bb701tJ3P51NaWlpYn9nZ2T32Fx8fr/j4eCulAwAAw1maaYmLi9OcOXPk8XhC6wKBgDwej/Lz8/vcTyAQUGdnpyQpKytLTqczrE+/3699+/ZZ6hMAAAxvlp/y7Ha7VVhYqJycHOXm5qqiokLt7e0qKiqSJC1fvlwTJ05UeXm5pC/PP8nJydG1116rzs5OvfHGG/rlL3+pbdu2SZKioqK0atUqPf7445oyZYqysrK0du1apaena/HixQO3pwAAwGiWQ8uSJUvU3Nys0tJSeb1eZWdnq7KyMnQibUNDg6Kjz0/gtLe364c//KGOHTumxMRETZs2Tf/1X/+lJUuWhNo8/PDDam9v17333qvW1lbddNNNqqysHPaXgAEAgL6zfJ+WSMR9WnrHfVoAIDJxn5ZBvk8LAACAXSz/PHQlqmqsCr0+1NqqpC8i+7lINyROsbsEAAAGHKEFAIAI8n//R3ko3Jpxq6X25eXlevXVV/Xxxx8rMTFR8+bN04YNGzR16tTBKfD/4OchAADQZ3v27NGKFSu0d+9e7d69W2fPntX8+fPV3t4+6GMz0wIAAPqssrIy7P2LL76oCRMmqKamJvRcwcHCTAsAAOi3trY2SdK4ceMGfSxCCwAA6JdAIKBVq1bpxhtv1PXXXz/o4/HzEAAA6JcVK1bo0KFDevfdd4dkPEILAACwrLi4WK+//rreeecdXX311UMyJqEFAAD0WTAY1P33369du3apqqpKWVlZQzY2oQUAAPTZihUrtGPHDv32t7/VmDFj5PV6JUnJyclKTEwc1LE5ERcAAPTZtm3b1NbWpltvvVVpaWmhZefOnYM+NjMtAABEEKt3qB1qdj5nmZkWAABgBEILAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACt/EHACCCnPr920M63phvfsNS+23btmnbtm369NNPJUnXXXedSktLtXDhwkGoLhwzLQAAoM+uvvpqrV+/XjU1NXrvvff0zW9+U9/5znf04YcfDvrYzLQAAIA+u/3228PeP/HEE9q2bZv27t2r6667blDHJrQAAIB+6e7u1iuvvKL29nbl5+cP+niEFgAAYMkHH3yg/Px8nTlzRqNHj9auXbs0ffr0QR+Xc1oAAIAlU6dOVV1dnfbt26f77rtPhYWFOnz48KCPy0wLAACwJC4uTpMnT5YkzZkzRwcOHNDPfvYzPfvss4M6LjMtAADgsgQCAXV2dg76OMy0AACAPispKdHChQt1zTXX6NSpU9qxY4eqqqr05ptvDvrYhBYAANBnTU1NWr58uT7//HMlJydr5syZevPNN/Wtb31r0McmtPRTyuHjdpfQq+i4QOj1qc9HS5LGTB38OxUCAC6f1TvUDrX//M//tG1szmkBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEboV2jZunWrMjMzlZCQoLy8PO3fv7/Xts8//7xuvvlmpaSkKCUlRS6X64L23/ve9xQVFRW2LFiwoD+lAQCAYcrybfx37twpt9ut7du3Ky8vTxUVFSooKNCRI0c0YcKEC9pXVVVp2bJlmjdvnhISErRhwwbNnz9fH374oSZOnBhqt2DBAv385z8PvY+Pj+/nLgEAYK76gy1DOl7WzNTL2n79+vUqKSnRypUrVVFRMTBF9cLyTMvTTz+te+65R0VFRZo+fbq2b9+ukSNH6oUXXuix/a9+9Sv98Ic/VHZ2tqZNm6b/+I//UCAQkMfjCWsXHx8vp9MZWlJSUvq3RwAAYEgcOHBAzz77rGbOnDkk41kKLV1dXaqpqZHL5TrfQXS0XC6Xqqur+9RHR0eHzp49q3HjxoWtr6qq0oQJEzR16lTdd999OnnyZK99dHZ2yu/3hy0AAGDonD59Wnfffbeef/75IZtosBRaWlpa1N3dLYfDEbbe4XDI6/X2qY/Vq1crPT09LPgsWLBAv/jFL+TxeLRhwwbt2bNHCxcuVHd3d499lJeXKzk5ObRkZGRY2Q0AAHCZVqxYoUWLFoV9nw82y+e0XI7169fr5ZdfVlVVlRISEkLrly5dGno9Y8YMzZw5U9dee62qqqp02223XdBPSUmJ3G536L3f7ye4AAAwRF5++WXV1tbqwIEDQzqupdCSmpqqmJgY+Xy+sPU+n09Op/Oi227atEnr16/XW2+9dcnfviZNmqTU1FR98sknPYaW+Ph4TtQFAMAGjY2NWrlypXbv3h02ATEULP08FBcXpzlz5oSdRHvupNr8/Pxet9u4caPWrVunyspK5eTkXHKcY8eO6eTJk0pLS7NSHgAAGGQ1NTVqamrSDTfcoNjYWMXGxmrPnj3avHmzYmNjez21YyBY/nnI7XarsLBQOTk5ys3NVUVFhdrb21VUVCRJWr58uSZOnKjy8nJJ0oYNG1RaWqodO3YoMzMzdO7L6NGjNXr0aJ0+fVqPPfaY7rjjDjmdTv3pT3/Sww8/rMmTJ6ugoGAAdxUAAFyu2267TR988EHYuqKiIk2bNk2rV69WTEzMoI1tObQsWbJEzc3NKi0tldfrVXZ2tiorK0Mn5zY0NCg6+vwEzrZt29TV1aU777wzrJ+ysjI9+uijiomJ0cGDB/XSSy+ptbVV6enpmj9/vtatW8dPQAAARJgxY8bo+uuvD1s3atQojR8//oL1A61fJ+IWFxeruLi4x8+qqqrC3n/66acX7SsxMVFvvvlmf8oAAABXkCG9eggAAFzc5d6h1g5fnbAYLDwwEQAAGIHQAgAAjEBoAQAARiC0AAAAIxBaAACAEQgtAADYKBgM2l3CoBuofSS0AABgg3N3ju3q6rK5ksHX0dEhSRoxYsRl9cN9WgAAsEFsbKxGjhyp5uZmjRgxIuxu8sNFMBhUR0eHmpqaNHbs2Mu+xT+hBQAAG0RFRSktLU319fX67LPP7C5nUI0dO1ZOp/Oy+yG0AABgk7i4OE2ZMmVY/0Q0YsSIAXuIIqEFAAAbRUdHKyEhwe4yjDD8fkADAADDEqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEYgtAAAACMQWgAAgBEILQAAwAiEFgAAYARCCwAAMAKhBQAAGIHQAgAAjEBoAQAARiC0AAAAIxBaAACAEQgtAADACLF2F2CyMx3pdpfQo5NdKaHXsdGJkqTEgy3KmplqV0kAAFw2ZloAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEboV2jZunWrMjMzlZCQoLy8PO3fv7/Xts8//7xuvvlmpaSkKCUlRS6X64L2wWBQpaWlSktLU2Jiolwul44ePdqf0gAAwDBlObTs3LlTbrdbZWVlqq2t1axZs1RQUKCmpqYe21dVVWnZsmV6++23VV1drYyMDM2fP1/Hjx8Ptdm4caM2b96s7du3a9++fRo1apQKCgp05syZ/u8ZAAAYVqKCwWDQygZ5eXmaO3eutmzZIkkKBALKyMjQ/fffrzVr1lxy++7ubqWkpGjLli1avny5gsGg0tPT9cADD+jBBx+UJLW1tcnhcOjFF1/U0qVLL9mn3+9XcnKy2tralJSUZGV3+qSqsSr0uq6xVUknDyrl8PGIvSOuM/b8HXEdSX+/I+43/h93xAUARBSr39+WZlq6urpUU1Mjl8t1voPoaLlcLlVXV/epj46ODp09e1bjxo2TJNXX18vr9Yb1mZycrLy8vF777OzslN/vD1sAAMDwZim0tLS0qLu7Ww6HI2y9w+GQ1+vtUx+rV69Wenp6KKSc285Kn+Xl5UpOTg4tGRkZVnYDAAAYaEivHlq/fr1efvll7dq1SwkJCf3up6SkRG1tbaGlsbFxAKsEAACRyNJTnlNTUxUTEyOfzxe23ufzyel0XnTbTZs2af369Xrrrbc0c+bM0Ppz2/l8PqWlpYX1mZ2d3WNf8fHxio+Pt1I6AAAwnKWZlri4OM2ZM0cejye0LhAIyOPxKD8/v9ftNm7cqHXr1qmyslI5OTlhn2VlZcnpdIb16ff7tW/fvov2CQAAriyWZlokye12q7CwUDk5OcrNzVVFRYXa29tVVFQkSVq+fLkmTpyo8vJySdKGDRtUWlqqHTt2KDMzM3SeyujRozV69GhFRUVp1apVevzxxzVlyhRlZWVp7dq1Sk9P1+LFiwduTwEAgNEsh5YlS5aoublZpaWl8nq9ys7OVmVlZehE2oaGBkVHn5/A2bZtm7q6unTnnXeG9VNWVqZHH31UkvTwww+rvb1d9957r1pbW3XTTTepsrLyss57AQAAw4vl+7REIu7TEo77tAAATDCo92kBAACwC6EFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEYgtAAAACMQWgAAgBEILQAAwAiEFgAAYARCCwAAMAKhBQAAGIHQAgAAjEBoAQAARiC0AAAAIxBaAACAEQgtAADACIQWAABgBEILAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEYgtAAAACMQWgAAgBEILQAAwAiEFgAAYARCCwAAMAKhBQAAGIHQAgAAjNCv0LJ161ZlZmYqISFBeXl52r9/f69tP/zwQ91xxx3KzMxUVFSUKioqLmjz6KOPKioqKmyZNm1af0oDAADDlOXQsnPnTrndbpWVlam2tlazZs1SQUGBmpqaemzf0dGhSZMmaf369XI6nb32e9111+nzzz8PLe+++67V0gAAwDBmObQ8/fTTuueee1RUVKTp06dr+/btGjlypF544YUe28+dO1dPPvmkli5dqvj4+F77jY2NldPpDC2pqalWSwMAAMOYpdDS1dWlmpoauVyu8x1ER8vlcqm6uvqyCjl69KjS09M1adIk3X333WpoaOi1bWdnp/x+f9gCAACGN0uhpaWlRd3d3XI4HGHrHQ6HvF5vv4vIy8vTiy++qMrKSm3btk319fW6+eabderUqR7bl5eXKzk5ObRkZGT0e2wAAGCGiLh6aOHChbrrrrs0c+ZMFRQU6I033lBra6t+85vf9Ni+pKREbW1toaWxsXGIKwYAAEMt1krj1NRUxcTEyOfzha33+XwXPcnWqrFjx+of/uEf9Mknn/T4eXx8/EXPjwEAAMOPpZmWuLg4zZkzRx6PJ7QuEAjI4/EoPz9/wIo6ffq0/vSnPyktLW3A+gQAAGazNNMiSW63W4WFhcrJyVFubq4qKirU3t6uoqIiSdLy5cs1ceJElZeXS/ry5N3Dhw+HXh8/flx1dXUaPXq0Jk+eLEl68MEHdfvtt+trX/uaTpw4obKyMsXExGjZsmUDtZ8AAMBwlkPLkiVL1NzcrNLSUnm9XmVnZ6uysjJ0cm5DQ4Oio89P4Jw4cUKzZ88Ovd+0aZM2bdqkW265RVVVVZKkY8eOadmyZTp58qSuuuoq3XTTTdq7d6+uuuqqy9w9AAAwXEQFg8Gg3UVcLr/fr+TkZLW1tSkpKWnA+69qrAq9rmtsVdLJg0o5fFxnOtIHfKyB4IxNCb12JCVKkhK/8f+UNZN73wAAIofV7++IuHoIAADgUggtAADACIQWAABgBEILAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEYgtAAAACMQWgAAgBEILQAAwAiEFgAAYARCCwAAMAKhBQAAGIHQAgAAjEBoAQAARoi1uwAMLp//C0lSW0Or/hTbbXM1l+aa7rC7BAARrv5gi90lWJI1M9XuEoYNZloAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEYgtAAAACMQWgAAgBEILQAAwAiEFgAAYARCCwAAMAKhBQAAGIHQAgAAjEBoAQAARiC0AAAAIxBaAACAEQgtAADACP0KLVu3blVmZqYSEhKUl5en/fv399r2ww8/1B133KHMzExFRUWpoqLisvsEAABXHsuhZefOnXK73SorK1Ntba1mzZqlgoICNTU19di+o6NDkyZN0vr16+V0OgekTwAAcOWJCgaDQSsb5OXlae7cudqyZYskKRAIKCMjQ/fff7/WrFlz0W0zMzO1atUqrVq1asD6lCS/36/k5GS1tbUpKSnJyu70SVVjVeh1XWOrkk4eVMrh4zrTkT7gYw0EZ2zKBevaZn9boyeNsaEaa1zTHXaXAAyI+oMtdpfQZ1kzU+0uwRKTjq2JhvLPg9Xvb0szLV1dXaqpqZHL5TrfQXS0XC6XqqurrVc7SH0CAIDhJ9ZK45aWFnV3d8vhCP+/YYfDoY8//rhfBfSnz87OTnV2dobe+/3+fo0NAADMYSm0RIry8nI99thjdpcBYKgd+Z3dFfTdsb9PZF89x946gGHE0s9DqampiomJkc/nC1vv8/l6Pcl2MPosKSlRW1tbaGlsbOzX2AAAwByWQktcXJzmzJkjj8cTWhcIBOTxeJSfn9+vAvrTZ3x8vJKSksIWAAAwvFn+ecjtdquwsFA5OTnKzc1VRUWF2tvbVVRUJElavny5Jk6cqPLycklfnmh7+PDh0Ovjx4+rrq5Oo0eP1uTJk/vUJwAAgOXQsmTJEjU3N6u0tFRer1fZ2dmqrKwMnUjb0NCg6OjzEzgnTpzQ7NmzQ+83bdqkTZs26ZZbblFVVVWf+gQAAOjXibjFxcUqLi7u8bNzQeSczMxM9eVWMBfrE8Pbodbzl7bHNo61r5A+uDXjVrtLuCxvHfZdulEE4b49AP4vnj0EAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADCCkQ9MBHDlOfX7t6XjH9pdRt+Nn2F3BcCww0wLAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjcPUQMEDqD7bYXcIlnW44FXo9etIYGytBJDHhzy4gEVqAAXHq92/rixNBu8u4pBHN7ZKks1O+bnMlw98XRxu+fPGXEfYW0keJM2faXQJwSfw8BAAAjEBoAQAARiC0AAAAIxBaAACAEQgtAADACIQWAABgBC55BgDgMh1q/sDuEiy5/iozn0JOaEFkOl5jdwU96/ii5/XHP5SibhjaWgDgCsPPQwAAwAiEFgAAYARCCwAAMAKhBQAAGIHQAgAAjMDVQ8Aw9pn/s7D3zZ1nJElt7VGSAVdofvH5qNDr8Sc/kE432FiNNW1fOL984Y+cf2a/lvQ1u0sALkvk/G0CMORGnvrU7hIuLjr+/OuTn9hXByLOFwcPhq84+Sd7Cvm72C+arW2QlDY4hfTRF58He/3sVEuUJGnMN78xVOX0GT8PAQAAIxBaAACAEQgtAADACIQWAABgBEILAAAwAlcPIaLUNbZKkpJOtttbSC/+3Hwg7P2kq768JDfudIPaguPtKGlY87Z1hl7/zd95kZb2cyTFX7oRLLnYk5Njv3I5v6xevQMjEVquECOOfqSEk3+zu4weXdX+8QXrOjNsKOQKklzfKEmK/+KkzZVYMNLuAgDYjdByhRh5ul5J+ovdZfRoZNfnF6zr1EQbKrlM/gv3I9LEf3HW7hIAoN84pwUAABiB0AIAAIxAaAEAAEYgtAAAACMQWgAAgBH6dfXQ1q1b9eSTT8rr9WrWrFl65plnlJub22v7V155RWvXrtWnn36qKVOmaMOGDfr2t78d+vx73/ueXnrppbBtCgoKVFlZ2Z/yAGDI+b5yH5kzf79Sq1Nn7CinR4HOi9z/yFM9dIX00cnOY6HXjqQEGytBpLA807Jz50653W6VlZWptrZWs2bNUkFBgZqamnps/4c//EHLli3TD37wA73//vtavHixFi9erEOHDoW1W7BggT7//PPQ8utf/7p/ewQAAIYly6Hl6aef1j333KOioiJNnz5d27dv18iRI/XCCy/02P5nP/uZFixYoIceekhf//rXtW7dOt1www3asmVLWLv4+Hg5nc7QkpKS0r89AgAAw5Kl0NLV1aWamhq5XK7zHURHy+Vyqbq656nF6urqsPbSlz/9fLV9VVWVJkyYoKlTp+q+++7TyZO936mzs7NTfr8/bAEAAMObpdDS0tKi7u5uORyOsPUOh0Ner7fHbbxe7yXbL1iwQL/4xS/k8Xi0YcMG7dmzRwsXLlR3d3ePfZaXlys5OTm0ZGRwz3cAAIa7iLiN/9KlS0OvZ8yYoZkzZ+raa69VVVWVbrvttgval5SUyO12h977/X6CCwAAw5ylmZbU1FTFxMTI5/OFrff5fHI6nT1u43Q6LbWXpEmTJik1NVWffPJJj5/Hx8crKSkpbAEAAMObpZmWuLg4zZkzRx6PR4sXL5YkBQIBeTweFRcX97hNfn6+PB6PVq1aFVq3e/du5efn9zrOsWPHdPLkSaWlpVkpD3/n/dtfe1zf2sODCQEAMIXlq4fcbreef/55vfTSS/roo4903333qb29XUVFRZKk5cuXq6SkJNR+5cqVqqys1FNPPaWPP/5Yjz76qN57771QyDl9+rQeeugh7d27V59++qk8Ho++853vaPLkySooKBig3QQAAKazfE7LkiVL1NzcrNLSUnm9XmVnZ6uysjJ0sm1DQ4Oio89noXnz5mnHjh36yU9+okceeURTpkzRa6+9puuvv16SFBMTo4MHD+qll15Sa2ur0tPTNX/+fK1bt07x8fEDtJsAAMB0/ToRt7i4uNefg6qqqi5Yd9ddd+muu+7qsX1iYqLefPPN/pQBAACuIDx7CAAAGIHQAgAAjEBoAQAARoiIm8sBpvpz85dPzU3xd4ae6ovBcaYj3e4SgD5rvcS/B3Y//furT/zOumqUTZVYQ2hBREo5fNzuEoABEf9Fk90lhIw827dg3TE6a5ArAfqHn4cAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIzAJc+IWNyXAxhY3r/9tU/tOjtHDHIlsPtS+Asuf49OPP862Pblf4985V4yUxcOblF9wEwLAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARuOT5CsIlxAAAkxFaAABh7L6HSM+4dwz4eQgAABiC0AIAAIxAaAEAAEYgtAAAACMQWgAAgBG4eggAEPFavzh76UYY9phpAQAARiC0AAAAIxBaAACAEQgtAADACIQWAABgBEILAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAIhBYAAGAEQgsAADACoQUAABiB0AIAAIxAaAEAAEboV2jZunWrMjMzlZCQoLy8PO3fv/+i7V955RVNmzZNCQkJmjFjht54442wz4PBoEpLS5WWlqbExES5XC4dPXq0P6UBAIBhynJo2blzp9xut8rKylRbW6tZs2apoKBATU1NPbb/wx/+oGXLlukHP/iB3n//fS1evFiLFy/WoUOHQm02btyozZs3a/v27dq3b59GjRqlgoICnTlzpv97BgAAhpWoYDAYtLJBXl6e5s6dqy1btkiSAoGAMjIydP/992vNmjUXtF+yZIna29v1+uuvh9b94z/+o7Kzs7V9+3YFg0Glp6frgQce0IMPPihJamtrk8Ph0IsvvqilS5desia/36/k5GS1tbUpKSnJyu70SVVjVeh1XWOrkk4eVMrh4zrTkT7gYwEAMNicsSlh7x1JiaHXGePaJEljcq8L32jqwgGvw+r3d6yVzru6ulRTU6OSkpLQuujoaLlcLlVXV/e4TXV1tdxud9i6goICvfbaa5Kk+vp6eb1euVyu0OfJycnKy8tTdXV1j6Gls7NTnZ2dofdtbV8eYL/fb2V3+qz9VHvo9Zn2Do3oOKP4M10608lMEADAPO1/C//+Oh13/rX/iy8/C57uCN9oEL5jz31v93X+xFJoaWlpUXd3txwOR9h6h8Ohjz/+uMdtvF5vj+29Xm/o83PremvzVeXl5XrssccuWJ+RkdG3HQEAABHj1KlTSk5OvmQ7S6ElUpSUlITN3gQCAf3lL3/R+PHjFRUVNWR1+P1+ZWRkqLGxcVB+lhqOOGbWcLys4XhZxzGzhuNlzaWOVzAY1KlTp5Se3rfTLSyFltTUVMXExMjn84Wt9/l8cjqdPW7jdDov2v7cf30+n9LS0sLaZGdn99hnfHy84uPjw9aNHTvWyq4MqKSkJP7wWsQxs4bjZQ3HyzqOmTUcL2sudrz6MsNyjqWrh+Li4jRnzhx5PJ7QukAgII/Ho/z8/B63yc/PD2svSbt37w61z8rKktPpDGvj9/u1b9++XvsEAABXHss/D7ndbhUWFionJ0e5ubmqqKhQe3u7ioqKJEnLly/XxIkTVV5eLklauXKlbrnlFj311FNatGiRXn75Zb333nt67rnnJElRUVFatWqVHn/8cU2ZMkVZWVlau3at0tPTtXjx4oHbUwAAYDTLoWXJkiVqbm5WaWmpvF6vsrOzVVlZGTqRtqGhQdHR5ydw5s2bpx07dugnP/mJHnnkEU2ZMkWvvfaarr/++lCbhx9+WO3t7br33nvV2tqqm266SZWVlUpISBiAXRw88fHxKisru+CnKvSOY2YNx8sajpd1HDNrOF7WDPTxsnyfFgAAADvw7CEAAGAEQgsAADACoQUAABiB0AIAAIxAaLkMW7duVWZmphISEpSXl6f9+/fbXVJEKi8v19y5czVmzBhNmDBBixcv1pEjR+wuyxjr168P3RoAvTt+/Lj+9V//VePHj1diYqJmzJih9957z+6yIlJ3d7fWrl2rrKwsJSYm6tprr9W6dev6/PyXK8E777yj22+/Xenp6YqKigo9L++cYDCo0tJSpaWlKTExUS6XS0ePHrWn2AhwseN19uxZrV69WjNmzNCoUaOUnp6u5cuX68SJE5bHIbT0086dO+V2u1VWVqba2lrNmjVLBQUFampqsru0iLNnzx6tWLFCe/fu1e7du3X27FnNnz9f7e3tl974CnfgwAE9++yzmjlzpt2lRLS//vWvuvHGGzVixAj97ne/0+HDh/XUU08pJSXl0htfgTZs2KBt27Zpy5Yt+uijj7RhwwZt3LhRzzzzjN2lRYz29nbNmjVLW7du7fHzjRs3avPmzdq+fbv27dunUaNGqaCgQGfOXJkP0r3Y8ero6FBtba3Wrl2r2tpavfrqqzpy5Ij++Z//2fpAQfRLbm5ucMWKFaH33d3dwfT09GB5ebmNVZmhqakpKCm4Z88eu0uJaKdOnQpOmTIluHv37uAtt9wSXLlypd0lRazVq1cHb7rpJrvLMMaiRYuC3//+98PW/cu//Evw7rvvtqmiyCYpuGvXrtD7QCAQdDqdwSeffDK0rrW1NRgfHx/89a9/bUOFkeWrx6sn+/fvD0oKfvbZZ5b6ZqalH7q6ulRTUyOXyxVaFx0dLZfLperqahsrM0NbW5skady4cTZXEtlWrFihRYsWhf05Q8/++7//Wzk5Obrrrrs0YcIEzZ49W88//7zdZUWsefPmyePx6I9//KMk6X//93/17rvvauHChTZXZob6+np5vd6wv5vJycnKy8vjO6CP2traFBUVZfm5gUY+5dluLS0t6u7uDt0F+ByHw6GPP/7YpqrMEAgEtGrVKt14441hd0VGuJdfflm1tbU6cOCA3aUY4c9//rO2bdsmt9utRx55RAcOHNC///u/Ky4uToWFhXaXF3HWrFkjv9+vadOmKSYmRt3d3XriiSd09913212aEbxeryT1+B1w7jP07syZM1q9erWWLVtm+aGThBYMqRUrVujQoUN699137S4lYjU2NmrlypXavXt3xD/KIlIEAgHl5OTopz/9qSRp9uzZOnTokLZv305o6cFvfvMb/epXv9KOHTt03XXXqa6uTqtWrVJ6ejrHC4Pq7Nmz+u53v6tgMKht27ZZ3p6fh/ohNTVVMTEx8vl8Yet9Pp+cTqdNVUW+4uJivf7663r77bd19dVX211OxKqpqVFTU5NuuOEGxcbGKjY2Vnv27NHmzZsVGxur7u5uu0uMOGlpaZo+fXrYuq9//etqaGiwqaLI9tBDD2nNmjVaunSpZsyYoX/7t3/Tj370o9CDbnFx5/6d5zvAmnOB5bPPPtPu3bstz7JIhJZ+iYuL05w5c+TxeELrAoGAPB6P8vPzbawsMgWDQRUXF2vXrl36/e9/r6ysLLtLimi33XabPvjgA9XV1YWWnJwc3X333aqrq1NMTIzdJUacG2+88YLL6P/4xz/qa1/7mk0VRbaOjo6wB9tKUkxMjAKBgE0VmSUrK0tOpzPsO8Dv92vfvn18B/TiXGA5evSo3nrrLY0fP75f/fDzUD+53W4VFhYqJydHubm5qqioUHt7u4qKiuwuLeKsWLFCO3bs0G9/+1uNGTMm9JtvcnKyEhMTba4u8owZM+aC831GjRql8ePHcx5QL370ox9p3rx5+ulPf6rvfve72r9/v5577jk999xzdpcWkW6//XY98cQTuuaaa3Tdddfp/fff19NPP63vf//7dpcWMU6fPq1PPvkk9L6+vl51dXUaN26crrnmGq1atUqPP/64pkyZoqysLK1du1bp6elavHixfUXb6GLHKy0tTXfeeadqa2v1+uuvq7u7O/Q9MG7cOMXFxfV9oH5f04TgM888E7zmmmuCcXFxwdzc3ODevXvtLikiSepx+fnPf253acbgkudL+5//+Z/g9ddfH4yPjw9OmzYt+Nxzz9ldUsTy+/3BlStXBq+55ppgQkJCcNKkScEf//jHwc7OTrtLixhvv/12j/9uFRYWBoPBLy97Xrt2bdDhcATj4+ODt912W/DIkSP2Fm2jix2v+vr6Xr8H3n77bUvjRAWD3AIRAABEPs5pAQAARiC0AAAAIxBaAACAEQgtAADACIQWAABgBEILAAAwAqEFAAAYgdACAACMQGgBAABGILQAAAAjEFoAAIARCC0AAMAI/x/DXnh3nUB+DAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx,epoch_rewards in enumerate(overall_rewards):\n",
    "    plt.hist([i.item() for i in epoch_rewards], density=True, alpha=0.3)\n",
    "plt.legend(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad9f84-64ad-4ac7-9367-afd3974f1a2c",
   "metadata": {},
   "source": [
    "### Compare Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eb8a23d-1c3f-4c74-b3e9-c372b1c5cb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This really</td>\n",
       "      <td>there is no more cliché or grand statement fr...</td>\n",
       "      <td>is passion and a love of the craft, and you</td>\n",
       "      <td>0.084087</td>\n",
       "      <td>10.838050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film</td>\n",
       "      <td>blowing experience. It will change you and lea...</td>\n",
       "      <td>\"The Football Manager\". It is set in the Ghan...</td>\n",
       "      <td>8.913700</td>\n",
       "      <td>3.289817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When i</td>\n",
       "      <td>and get it to print letters i get 1.\\nDon't u...</td>\n",
       "      <td>the result, it's give me the output tiger. bu...</td>\n",
       "      <td>0.550711</td>\n",
       "      <td>0.451357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The only aspect of this film that</td>\n",
       "      <td>such as those scenes of typical Hollywood sex...</td>\n",
       "      <td>brothers' musical talents, which is always ve...</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>9.614667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE SC</td>\n",
       "      <td>The Art of Skinning, Sutton delves into philo...</td>\n",
       "      <td>ETradsheinshowbacktheartshowproductshows</td>\n",
       "      <td>5.689440</td>\n",
       "      <td>0.192083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bette Midler is again</td>\n",
       "      <td>ing a cast entirely of Los Angeles actors in h...</td>\n",
       "      <td>star and photographer Nicholas Will, helping ...</td>\n",
       "      <td>5.354937</td>\n",
       "      <td>10.702723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Firstly, this is simply the</td>\n",
       "      <td>. But more significantly, COVID-19 has left li...</td>\n",
       "      <td>The word comes from two Latin words, for they...</td>\n",
       "      <td>0.529174</td>\n",
       "      <td>4.980739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Or at least one of</td>\n",
       "      <td>this approach was not sustainable. I would of...</td>\n",
       "      <td>in their face. Above all, we must try not to</td>\n",
       "      <td>0.691320</td>\n",
       "      <td>0.421196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I read in the papers that</td>\n",
       "      <td>sociology papers you have to look at somethin...</td>\n",
       "      <td>have been going on anyway, and you've been wo...</td>\n",
       "      <td>0.225386</td>\n",
       "      <td>0.488963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Don't get me wrong</td>\n",
       "      <td>, it is a case of the wild boar the size of a ...</td>\n",
       "      <td>, I still love playing PC games and watching m...</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>4.174393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When a comedy movie</td>\n",
       "      <td>is shown, it is important to take time for yo...</td>\n",
       "      <td>comes on, we can't help but laugh on cue. Lau...</td>\n",
       "      <td>6.828042</td>\n",
       "      <td>4.455914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A great addition</td>\n",
       "      <td>daylight savings time, make your time outdoor...</td>\n",
       "      <td>you're pressed, wrap this eye cream between y...</td>\n",
       "      <td>9.657653</td>\n",
       "      <td>9.369710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Warped take on</td>\n",
       "      <td>like this is to put together a project. This ...</td>\n",
       "      <td>in both Japan and France. Fantastic additions...</td>\n",
       "      <td>4.956551</td>\n",
       "      <td>10.402567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is one of the very worst</td>\n",
       "      <td>world. In advance of this condition happening...</td>\n",
       "      <td>fat and sugar, both of which aid in UTI</td>\n",
       "      <td>1.255517</td>\n",
       "      <td>1.158483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Any movie that portrays</td>\n",
       "      <td>a boyfriend from Extremadura. We will get</td>\n",
       "      <td>rukh Khan, Naga Wilson, and others</td>\n",
       "      <td>-0.335160</td>\n",
       "      <td>0.236459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This God forsaken film</td>\n",
       "      <td>needlessly terrible. Won't sell in 1978, for ...</td>\n",
       "      <td>ano's artful tribute to all things fair and no...</td>\n",
       "      <td>1.147275</td>\n",
       "      <td>8.876408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                query  \\\n",
       "0                         This really   \n",
       "1                           This film   \n",
       "2                              When i   \n",
       "3   The only aspect of this film that   \n",
       "4                              THE SC   \n",
       "5               Bette Midler is again   \n",
       "6         Firstly, this is simply the   \n",
       "7                  Or at least one of   \n",
       "8           I read in the papers that   \n",
       "9                  Don't get me wrong   \n",
       "10                When a comedy movie   \n",
       "11                   A great addition   \n",
       "12                     Warped take on   \n",
       "13      This is one of the very worst   \n",
       "14            Any movie that portrays   \n",
       "15             This God forsaken film   \n",
       "\n",
       "                                    response (before)  \\\n",
       "0    there is no more cliché or grand statement fr...   \n",
       "1   blowing experience. It will change you and lea...   \n",
       "2    and get it to print letters i get 1.\\nDon't u...   \n",
       "3    such as those scenes of typical Hollywood sex...   \n",
       "4    The Art of Skinning, Sutton delves into philo...   \n",
       "5   ing a cast entirely of Los Angeles actors in h...   \n",
       "6   . But more significantly, COVID-19 has left li...   \n",
       "7    this approach was not sustainable. I would of...   \n",
       "8    sociology papers you have to look at somethin...   \n",
       "9   , it is a case of the wild boar the size of a ...   \n",
       "10   is shown, it is important to take time for yo...   \n",
       "11   daylight savings time, make your time outdoor...   \n",
       "12   like this is to put together a project. This ...   \n",
       "13   world. In advance of this condition happening...   \n",
       "14          a boyfriend from Extremadura. We will get   \n",
       "15   needlessly terrible. Won't sell in 1978, for ...   \n",
       "\n",
       "                                     response (after)  rewards (before)  \\\n",
       "0         is passion and a love of the craft, and you          0.084087   \n",
       "1    \"The Football Manager\". It is set in the Ghan...          8.913700   \n",
       "2    the result, it's give me the output tiger. bu...          0.550711   \n",
       "3    brothers' musical talents, which is always ve...          0.989781   \n",
       "4            ETradsheinshowbacktheartshowproductshows          5.689440   \n",
       "5    star and photographer Nicholas Will, helping ...          5.354937   \n",
       "6    The word comes from two Latin words, for they...          0.529174   \n",
       "7        in their face. Above all, we must try not to          0.691320   \n",
       "8    have been going on anyway, and you've been wo...          0.225386   \n",
       "9   , I still love playing PC games and watching m...          0.050499   \n",
       "10   comes on, we can't help but laugh on cue. Lau...          6.828042   \n",
       "11   you're pressed, wrap this eye cream between y...          9.657653   \n",
       "12   in both Japan and France. Fantastic additions...          4.956551   \n",
       "13            fat and sugar, both of which aid in UTI          1.255517   \n",
       "14                 rukh Khan, Naga Wilson, and others         -0.335160   \n",
       "15  ano's artful tribute to all things fair and no...          1.147275   \n",
       "\n",
       "    rewards (after)  \n",
       "0         10.838050  \n",
       "1          3.289817  \n",
       "2          0.451357  \n",
       "3          9.614667  \n",
       "4          0.192083  \n",
       "5         10.702723  \n",
       "6          4.980739  \n",
       "7          0.421196  \n",
       "8          0.488963  \n",
       "9          4.174393  \n",
       "10         4.455914  \n",
       "11         9.369710  \n",
       "12        10.402567  \n",
       "13         1.158483  \n",
       "14         0.236459  \n",
       "15         8.876408  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "game_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from phi2 and phi2_ref\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        # max_new_tokens=gen_len,\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        input_ids=torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
    "        # max_new_tokens=gen_len,\n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "game_data[\"response (before)\"] = [\n",
    "    tokenizer.decode(response_tensors_ref[i]) for i in range(bs)\n",
    "]\n",
    "game_data[\"response (after)\"] = [\n",
    "    tokenizer.decode(response_tensors[i]) for i in range(bs)\n",
    "]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
    "# game_data[\"rewards (before)\"] = [\n",
    "#     output[1][\"score\"] for output in sentiment_pipe(texts, **sentiment_pipe_kwargs)\n",
    "# ]\n",
    "game_data[\"rewards (before)\"]=list()\n",
    "for output in sentiment_pipe(texts, **sentiment_pipe_kwargs):\n",
    "        if output[0]['score']>output[1]['score']:\n",
    "            if output[0]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (before)\"].append(4*output[0]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (before)\"].append(0.5*output[0]['score'])\n",
    "        elif output[1]['score']>output[0]['score']:\n",
    "            if output[1]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (before)\"].append(t4*output[1]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (before)\"].append(0.25*output[0]['score'])\n",
    "\n",
    "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
    "# game_data[\"rewards (after)\"] = [\n",
    "#     output[1][\"score\"] for output in sentiment_pipe(texts, **sentiment_pipe_kwargs)\n",
    "# ]\n",
    "game_data[\"rewards (after)\"]=list()\n",
    "for output in sentiment_pipe(texts, **sentiment_pipe_kwargs):\n",
    "        if output[0]['score']>output[1]['score']:\n",
    "            if output[0]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (after)\"].append(4*output[0]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (after)\"].append(0.5*output[0]['score'])\n",
    "        elif output[1]['score']>output[0]['score']:\n",
    "            if output[1]['label'] == 'POSITIVE':\n",
    "                game_data[\"rewards (after)\"].append(4*output[1]['score'])\n",
    "            else:\n",
    "                game_data[\"rewards (after)\"].append(0.25*output[0]['score'])\n",
    "\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(game_data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c96b07-71f0-4636-ab36-d505f7fc7b7a",
   "metadata": {},
   "source": [
    "### Save Aligned Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "645c5b46-b4e7-4071-84ed-4e14f371e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aligned-phi-2/tokenizer_config.json',\n",
       " 'aligned-phi-2/special_tokens_map.json',\n",
       " 'aligned-phi-2/vocab.json',\n",
       " 'aligned-phi-2/merges.txt',\n",
       " 'aligned-phi-2/added_tokens.json',\n",
       " 'aligned-phi-2/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(ALIGNED_MODEL_NAME)\n",
    "tokenizer.save_pretrained(ALIGNED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc1ed0ff-125e-4441-8b79-9405bd2a9d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1360f65ebb28488f97d1972ab38999f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f7ee92a36d4663bc9e6b500a538b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51069cfa9f3941d0a3f65039a8c5c83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ad2a23fe214cfd9ba3bbed81e67e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffaea67ee92401fb30081abc27184ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/raghavbali/aligned-phi-2/commit/4e5eb398531c419a377d6f0ae6bd75ffbeaab0c7', commit_message='PPO alignment done', commit_description='', oid='4e5eb398531c419a377d6f0ae6bd75ffbeaab0c7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment if you would like to push to HF Hub\n",
    "# model.push_to_hub(ALIGNED_MODEL_NAME,commit_message=\"PPO alignment done\")\n",
    "# tokenizer.push_to_hub(ALIGNED_MODEL_NAME,commit_message=\"PPO alignment done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff932ed8-2588-4a97-aed2-b027185a629e",
   "metadata": {},
   "source": [
    "## Generate and Compare Aligned vs Non-Aligned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e389057f-53aa-4071-8dd2-d3312cbaaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb094076-ff1e-4e71-b6f9-33b3a6e60403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aligned-phi-2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking if we are still refering to same model\n",
    "ALIGNED_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dab01114-b221-4cde-a84d-55bf4f250460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458b06dfc7dc46ba9ce207c331586531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7213deb302f4efea286bc508eb9f7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48ab41ff0484802b39f4a146ebabb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e106af03c04b1c86962d598b2261eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa2f76d749840ed897484d09867ae4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f47b51640e4634bb8dd08f9b2d302a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87794413e3b54bfab2bdf615cbe10a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at raghavbali/aligned-phi-2 were not used when initializing PhiForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80770ecaa895491c9939b5918d850d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.phi.modeling_phi.PhiForCausalLM'> model is loaded from 'raghavbali/aligned-phi-2', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635087ea7a824402889f80c8063cd2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5934900ecc664dee8afbf69addade27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/1.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226a7fde6150497c88f076240f472fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7d486742c749bf86d4a8d8d3e264ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94ad25de94c43e6bf171556f97586c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ab5f777b62496988250fd08b7b5752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3015281cc974e58a425b3240e58da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eae7f92625432e8b6c0e647846d740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hub_model = AutoModelForCausalLMWithValueHead.from_pretrained(f'raghavbali/{ALIGNED_MODEL_NAME}',\n",
    "                                                              cache_dir=\"/workspace/\")\n",
    "# create a reference model\n",
    "hub_tokenizer = AutoTokenizer.from_pretrained(f'raghavbali/{ALIGNED_MODEL_NAME}',\n",
    "                                              cache_dir=\"/workspace/\")\n",
    "\n",
    "hub_tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8fd2f48-1147-4bb4-95f0-6fc2342a2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"If I have to review this movie, I would\",\n",
    "    \"The actors in this movie\",\n",
    "    \"The makers of this movie\",\n",
    "    \"I went to this movie for\",\n",
    "    \"The thing about this movie\",\n",
    "    \"Here are my 2 cents on the movie\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bb1c4e6-3a0c-4f0c-9649-e701d00591b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If I have to review this movie, I would say the best part of this movie is how beautiful it is and how well it shows the lives of the people of the time"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If I have to review this movie, I would give it 3 stars. It had some funny moments and a good storyline, but there were also some parts that felt a bit"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The actors in this movie are amazing! They bring their characters to life and make us feel like we are a part of the story. We can feel"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The actors in this movie were very talented. They made us feel like we were right there in the park, watching all the exciting things that were happening"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The makers of this movie have done a great job in bringing the story of the American Revolution to life. We can learn a lot about this important time"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The makers of this movie are from a place called Kerala, which is in India. The movie is in a language called Malayalam, which they"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I went to this movie for the first time and it left a deep impression on me\".\n",
       "\n",
       "Plot\n",
       "\n",
       "The film is narrated by a young boy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I went to this movie for my friends last week and it was terrible. The plot was confusing and the acting was terrible. It was a waste of money"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The thing about this movie is that it's not like a regular movie. It's more like a big show where the actors play their roles really well"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The thing about this movie is that it's not just about winning a competition. It's about the journey and the friendships you make along the way."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n",
      "----ALIGNED-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are my 2 cents on the movie.\n",
       "The movie shows a lot of what the people in the movie go through. I have been at many of the events"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- NON-ALIGNEDD-MODEL ----\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are my 2 cents on the movie, which I just saw. First, I was very impressed with the animation quality, especially when I saw the characters in the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- END ----\n"
     ]
    }
   ],
   "source": [
    "for review in reviews:\n",
    "    inputs = hub_tokenizer(review, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "    print(\"----ALIGNED-MODEL ----\")\n",
    "    outputs = hub_model.generate(**inputs,max_new_tokens=25,temperature=0.8,do_sample=True)\n",
    "    display(Markdown((tokenizer.decode(outputs[0], skip_special_tokens=True))))\n",
    "    print(\"---- NON-ALIGNEDD-MODEL ----\")\n",
    "    outputs = ref_model.generate(**inputs, max_new_tokens=25,temperature=0.8,do_sample=True)\n",
    "    display(Markdown((tokenizer.decode(outputs[0], skip_special_tokens=True))))\n",
    "    print(\"---- END ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734efdf-4b6d-48ba-82f7-96d376a84a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
